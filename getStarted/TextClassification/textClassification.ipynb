{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with PySpark \n",
    "- Multiclass Text Classification\n",
    "Task\n",
    "- Predict the subject category given a course title or text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 16:56:57 WARN Utils: Your hostname, iamhimanshu0 resolves to a loopback address: 127.0.1.1; using 192.168.43.239 instead (on interface wlo1)\n",
      "22/03/22 16:56:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/03/22 16:56:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(master='local[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.43.239:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lunch UI\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark seassion\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Text Classifier\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+-------+-----+---------------+-----------+------------+------------------+----------------+--------------------+----------------+--------------------+\n",
      "|_c0|course_id|        course_title|                 url|is_paid|price|num_subscribers|num_reviews|num_lectures|             level|content_duration| published_timestamp|         subject|  clean_course_title|\n",
      "+---+---------+--------------------+--------------------+-------+-----+---------------+-----------+------------+------------------+----------------+--------------------+----------------+--------------------+\n",
      "|  0|  1070968|Ultimate Investme...|https://www.udemy...|   True|  200|           2147|         23|          51|        All Levels|       1.5 hours|2017-01-18T20:58:58Z|Business Finance|Ultimate Investme...|\n",
      "|  1|  1113822|Complete GST Cour...|https://www.udemy...|   True|   75|           2792|        923|         274|        All Levels|        39 hours|2017-03-09T16:34:20Z|Business Finance|Complete GST Cour...|\n",
      "|  2|  1006314|Financial Modelin...|https://www.udemy...|   True|   45|           2174|         74|          51|Intermediate Level|       2.5 hours|2016-12-19T19:26:30Z|Business Finance|Financial Modelin...|\n",
      "|  3|  1210588|Beginner to Pro -...|https://www.udemy...|   True|   95|           2451|         11|          36|        All Levels|         3 hours|2017-05-30T20:07:24Z|Business Finance|Beginner Pro  Fin...|\n",
      "|  4|  1011058|How To Maximize Y...|https://www.udemy...|   True|  200|           1276|         45|          26|Intermediate Level|         2 hours|2016-12-13T14:57:18Z|Business Finance|Maximize Profits ...|\n",
      "+---+---------+--------------------+--------------------+-------+-----+---------------+-----------+------------+------------------+----------------+--------------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 17:00:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , course_id, course_title, url, is_paid, price, num_subscribers, num_reviews, num_lectures, level, content_duration, published_timestamp, subject, clean_course_title\n",
      " Schema: _c0, course_id, course_title, url, is_paid, price, num_subscribers, num_reviews, num_lectures, level, content_duration, published_timestamp, subject, clean_course_title\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/himanshu/Desktop/sparkLearn/getStarted/TextClassification/udemy.csv\n"
     ]
    }
   ],
   "source": [
    "# read the dataset and load\n",
    "df = spark.read.csv('udemy.csv',header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'course_id',\n",
       " 'course_title',\n",
       " 'url',\n",
       " 'is_paid',\n",
       " 'price',\n",
       " 'num_subscribers',\n",
       " 'num_reviews',\n",
       " 'num_lectures',\n",
       " 'level',\n",
       " 'content_duration',\n",
       " 'published_timestamp',\n",
       " 'subject',\n",
       " 'clean_course_title']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('course_title','subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|        course_title|         subject|\n",
      "+--------------------+----------------+\n",
      "|Ultimate Investme...|Business Finance|\n",
      "|Complete GST Cour...|Business Finance|\n",
      "|Financial Modelin...|Business Finance|\n",
      "|Beginner to Pro -...|Business Finance|\n",
      "|How To Maximize Y...|Business Finance|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             subject|count|\n",
      "+--------------------+-----+\n",
      "|     Web Development| 1200|\n",
      "|    Business Finance| 1198|\n",
      "| Musical Instruments|  676|\n",
      "|      Graphic Design|  603|\n",
      "|                null|    6|\n",
      "|Multiply returns ...|    1|\n",
      "|play Electric Gui...|    1|\n",
      "|Learn Play Fernan...|    1|\n",
      "|Introduction Guit...|    1|\n",
      "|Learn Classical G...|    1|\n",
      "|Aprende tocar el ...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupby('subject').count().sort(\"count\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting values count using pandas\n",
    "# df.toPandas()['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.toPandas()['subject'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "df = df.dropna(subset= ['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.toPandas()['subject'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|        course_title|         subject|\n",
      "+--------------------+----------------+\n",
      "|Ultimate Investme...|Business Finance|\n",
      "|Complete GST Cour...|Business Finance|\n",
      "|Financial Modelin...|Business Finance|\n",
      "|Beginner to Pro -...|Business Finance|\n",
      "|How To Maximize Y...|Business Finance|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "build features \n",
    "+ count vectorizer\n",
    "+ tfIDF\n",
    "+ wordEmbeddings\n",
    "+ hashingTF\n",
    "+ etc...\n",
    "\n",
    "We have 2 things in Pipeline stages\n",
    "- Transformer\n",
    "- Estimator\n",
    "\n",
    "**Transformer** (Data to Data)\n",
    "\n",
    "Function that takes data and fit, transform them into augmented data or features\n",
    "i.e Extractors, Vectorizer, Scalers (Tokenizer, StopwordRemover, CountVectorizer, IDF)\n",
    "\n",
    "**Estimator** (Data to model)\n",
    "\n",
    "Function that takes data as input and fit the data and produces a model we can use to predict\n",
    "i.e LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stages for the pipeline\n",
    "tokenizer = Tokenizer(inputCol='course_title', outputCol='mytokens')\n",
    "stopwordRemover = StopWordsRemover(inputCol='mytokens',outputCol='filtered_tokens')\n",
    "vectorizer = CountVectorizer(inputCol='filtered_tokens',outputCol='rawFeatures')\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='vectorizedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# work on taget variable (subject)\n",
    "# label encoding/indexing\n",
    "labelEncoder = StringIndexer(inputCol='subject',outputCol='label').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+\n",
      "|        course_title|         subject|label|\n",
      "+--------------------+----------------+-----+\n",
      "|Ultimate Investme...|Business Finance|  1.0|\n",
      "|Complete GST Cour...|Business Finance|  1.0|\n",
      "|Financial Modelin...|Business Finance|  1.0|\n",
      "|Beginner to Pro -...|Business Finance|  1.0|\n",
      "|How To Maximize Y...|Business Finance|  1.0|\n",
      "+--------------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelEncoder.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelEncoder.labels\n",
    "# making dict to labels\n",
    "label_dict =  {\n",
    " 'Web Development':0.0,\n",
    " 'Business Finance':1.0,\n",
    " 'Musical Instruments':2.0,\n",
    " 'Graphic Design':3.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+\n",
      "|        course_title|         subject|label|\n",
      "+--------------------+----------------+-----+\n",
      "|Ultimate Investme...|Business Finance|  1.0|\n",
      "|Complete GST Cour...|Business Finance|  1.0|\n",
      "|Financial Modelin...|Business Finance|  1.0|\n",
      "|Beginner to Pro -...|Business Finance|  1.0|\n",
      "|How To Maximize Y...|Business Finance|  1.0|\n",
      "+--------------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = labelEncoder.transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "(train_df, test_df) = df.randomSplit((0.7,0.3),seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|        course_title|            subject|label|\n",
      "+--------------------+-------------------+-----+\n",
      "|#1 Piano Hand Coo...|Musical Instruments|  2.0|\n",
      "|#10 Hand Coordina...|Musical Instruments|  2.0|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning model (Estimator) (data to model)\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='vectorizedFeatures',\n",
    "                        labelCol = 'label'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=[tokenizer, stopwordRemover, vectorizer, idf, lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Param(parent='Pipeline_7911e419495d', name='stages', doc='a list of pipeline stages')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 17:36:47 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/03/22 17:36:47 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "# model building\n",
    "lr_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_e1cdf1893748"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicction on test data\n",
    "predictions = lr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['course_title',\n",
       " 'subject',\n",
       " 'label',\n",
       " 'mytokens',\n",
       " 'filtered_tokens',\n",
       " 'rawFeatures',\n",
       " 'vectorizedFeatures',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions.show()\n",
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-----+----------+\n",
      "|       rawPrediction|         probability|            subject|label|prediction|\n",
      "+--------------------+--------------------+-------------------+-----+----------+\n",
      "|[8.30964874634511...|[0.87877993991729...|Musical Instruments|  2.0|       0.0|\n",
      "|[-1.3744065857781...|[1.90975343878318...|Musical Instruments|  2.0|       2.0|\n",
      "|[0.60822716351824...|[3.28451283099288...|Musical Instruments|  2.0|       2.0|\n",
      "|[-1.0584564885297...|[3.70732079181542...|   Business Finance|  1.0|       1.0|\n",
      "|[24.6296077836821...|[0.99999999906211...|    Web Development|  0.0|       0.0|\n",
      "|[22.0136686708729...|[0.99999999049941...|    Web Development|  0.0|       0.0|\n",
      "|[19.9225858177008...|[0.99999995276066...|    Web Development|  0.0|       0.0|\n",
      "|[-5.7386799100009...|[5.78822181193782...|Musical Instruments|  2.0|       2.0|\n",
      "|[-19.060576929776...|[1.71813778453453...|     Graphic Design|  3.0|       3.0|\n",
      "|[-2.4736166619785...|[1.84538870784594...|Musical Instruments|  2.0|       2.0|\n",
      "+--------------------+--------------------+-------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('rawPrediction', 'probability','subject','label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model evaluation\n",
    "+ Accuracy\n",
    "+ Precision\n",
    "+ F1Score\n",
    "+ etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.70354557551958"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method 2:\n",
    " precision, f1score classification report\n",
    "\"\"\"\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_metric = MulticlassMetrics(predictions['label','prediction'].rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9182509505703422\n",
      "precision  0.9544159544159544\n",
      "f1Score  0.9178082191780822\n",
      "recall  0.8839050131926122\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \", lr_metric.accuracy)\n",
    "print(\"precision \", lr_metric.precision(1.0))\n",
    "print(\"f1Score \", lr_metric.fMeasure(1.0))\n",
    "print(\"recall \", lr_metric.recall(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "- convert to pandas\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predictions.select('label')\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_predict = predictions.select('prediction')\n",
    "y_predict = y_predict.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[319,  12,   1,   4,   0,   0],\n",
       "       [ 11, 335,   3,   2,   0,   0],\n",
       "       [  8,  13, 156,   1,   0,   0],\n",
       "       [  8,  17,   4, 156,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_predict)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### making prediction on one sample\n",
    "+ sample as df\n",
    "+ apply pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|        course_title| _2|\n",
      "+--------------------+---+\n",
      "|Building Machine ...| {}|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exl = spark.createDataFrame([ \n",
    "    (\"Building Machine Learning Apps with Python and PySpark\", StringType())\n",
    "], \n",
    "#column name\n",
    "['course_title']\n",
    ")\n",
    "exl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+---+\n",
      "|course_title                                          |_2 |\n",
      "+------------------------------------------------------+---+\n",
      "|Building Machine Learning Apps with Python and PySpark|{} |\n",
      "+------------------------------------------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show fill\n",
    "exl.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|        course_title| _2|            mytokens|     filtered_tokens|         rawFeatures|  vectorizedFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Building Machine ...| {}|[building, machin...|[building, machin...|(3669,[57,79,115,...|(3669,[57,79,115,...|[14.7174498131555...|[0.99999814636182...|       0.0|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# making prediction\n",
    "prediction_ex1 = lr_model.transform(exl)\n",
    "prediction_ex1.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['course_title',\n",
       " '_2',\n",
       " 'mytokens',\n",
       " 'filtered_tokens',\n",
       " 'rawFeatures',\n",
       " 'vectorizedFeatures',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_ex1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|        course_title|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|Building Machine ...|[14.7174498131555...|[0.99999814636182...|       0.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_ex1.select('course_title','rawPrediction','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Web Development': 0.0,\n",
       " 'Business Finance': 1.0,\n",
       " 'Musical Instruments': 2.0,\n",
       " 'Graphic Design': 3.0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save and load the model\n",
    "modelPath  = \"models/pyspark_lr_model\"\n",
    "lr_model.write().save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pickled model \n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "presistedModel  =PipelineModel.load(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|        course_title| _2|            mytokens|     filtered_tokens|         rawFeatures|  vectorizedFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Building Machine ...| {}|[building, machin...|[building, machin...|(3669,[57,79,115,...|(3669,[57,79,115,...|[14.7174498131555...|[0.99999814636182...|       0.0|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laodModel\n",
    "# making prediction\n",
    "loadModel = presistedModel.transform(exl)\n",
    "loadModel.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|        course_title|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|Building Machine ...|[14.7174498131555...|[0.99999814636182...|       0.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loadModel.select('course_title','rawPrediction','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82dc0c27685d313ea4c02f56aa37741b330462340c1074df74913ea85720511c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
