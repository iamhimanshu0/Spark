{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroNLP Pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqdWa0KzNYni"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Natural Language Processing with PySpark\n",
        "\n",
        "NLP Tools\n",
        "- Tokenizer\n",
        "- StopWordRemoval\n",
        "- n-grams\n",
        "- TF-IDF\n",
        "- CountVectorizer"
      ],
      "metadata": {
        "id": "dh01ZVusNfSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip >> smsspamcollection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLE4868kNrRo",
        "outputId": "df6bddad-c2a5-4366-8a40-f8d71d2da01c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  198k  100  198k    0     0   185k      0  0:00:01  0:00:01 --:--:--  185k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt install unzip\n",
        "!unzip /content/smsspamcollection.zip"
      ],
      "metadata": {
        "id": "eFsdVxX_N4K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "iGjkv3_VPV7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "Yiy1nC4kOBWl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"NLP Learning\").getOrCreate()"
      ],
      "metadata": {
        "id": "MT3oCA9KOTXc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer"
      ],
      "metadata": {
        "id": "TGMFA6PPP1mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import IntegerType"
      ],
      "metadata": {
        "id": "IagC1EmEPq2e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df = spark.createDataFrame(\n",
        "    [\n",
        "     (0,\"hello i am happy to be learning Apache Spark\"),\n",
        "     (1, \"I enjoy learning about python and javascript progamming\"),\n",
        "     (2, \"i am familiar with Machine Learning applications\"),\n",
        "     (3, \"here, is,a,list,of,words\")\n",
        "    ],\n",
        "    ['id','sentences']\n",
        ")\n",
        "\n",
        "sent_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDaNcXvNQPIP",
        "outputId": "67873bc4-8de3-427e-b308-376b72716d70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------------------------------+\n",
            "|id |sentences                                              |\n",
            "+---+-------------------------------------------------------+\n",
            "|0  |hello i am happy to be learning Apache Spark           |\n",
            "|1  |I enjoy learning about python and javascript progamming|\n",
            "|2  |i am familiar with Machine Learning applications       |\n",
            "|3  |here, is,a,list,of,words                               |\n",
            "+---+-------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(inputCol='sentences', outputCol='tokenOutput')\n",
        "regexTokenizer = RegexTokenizer(inputCol='sentences', outputCol='regxOutput',pattern=\"\\\\W\")\n",
        "\n",
        "# word count for each sentences\n",
        "countTokens = udf(lambda w:len(w), IntegerType())\n"
      ],
      "metadata": {
        "id": "1-scKI1gQN0N"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.transform(sent_df)\n",
        "tokenized.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsYyYpFZRyxY",
        "outputId": "67b99ad3-c3b9-4cca-fce9-4d055314b7f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "|id |sentences                                              |tokenOutput                                                     |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "|0  |hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |\n",
            "|1  |I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|\n",
            "|2  |i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |\n",
            "|3  |here, is,a,list,of,words                               |[here,, is,a,list,of,words]                                     |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized.select('sentences','tokenOutput').withColumn(\"tokens\", countTokens(col('tokenOutput'))).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17RZsvZpR-st",
        "outputId": "a5704747-cba5-4322-950f-a7f3a6869740"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------+----------------------------------------------------------------+------+\n",
            "|sentences                                              |tokenOutput                                                     |tokens|\n",
            "+-------------------------------------------------------+----------------------------------------------------------------+------+\n",
            "|hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |9     |\n",
            "|I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|8     |\n",
            "|i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |7     |\n",
            "|here, is,a,list,of,words                               |[here,, is,a,list,of,words]                                     |2     |\n",
            "+-------------------------------------------------------+----------------------------------------------------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regexTokenized = regexTokenizer.transform(sent_df)\n",
        "regexTokenized.select('sentences','regxOutput').withColumn(\"tokens\", countTokens(col('regxOutput'))).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQF0F_PRSpOe",
        "outputId": "e30e518a-79ef-4b9d-f1c4-9384f0cce4bb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------+----------------------------------------------------------------+------+\n",
            "|sentences                                              |regxOutput                                                      |tokens|\n",
            "+-------------------------------------------------------+----------------------------------------------------------------+------+\n",
            "|hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |9     |\n",
            "|I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|8     |\n",
            "|i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |7     |\n",
            "|here, is,a,list,of,words                               |[here, is, a, list, of, words]                                  |6     |\n",
            "+-------------------------------------------------------+----------------------------------------------------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stop Word Removal"
      ],
      "metadata": {
        "id": "HdWxABYhUxZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StopWordsRemover"
      ],
      "metadata": {
        "id": "tSLdM_agUPOn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remover = StopWordsRemover(inputCol='regxOutput',outputCol='cleaned')\n",
        "remover.transform(regexTokenized).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Rs09ADU60y",
        "outputId": "c1effd73-d83f-4ae0-b4da-d6543263353e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------------------------------+----------------------------------------------------------------+-------------------------------------------------+\n",
            "|id |sentences                                              |regxOutput                                                      |cleaned                                          |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+-------------------------------------------------+\n",
            "|0  |hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |[hello, happy, learning, apache, spark]          |\n",
            "|1  |I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|[enjoy, learning, python, javascript, progamming]|\n",
            "|2  |i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |[familiar, machine, learning, applications]      |\n",
            "|3  |here, is,a,list,of,words                               |[here, is, a, list, of, words]                                  |[list, words]                                    |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+-------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### n-gram"
      ],
      "metadata": {
        "id": "db9stWVUaHy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import NGram"
      ],
      "metadata": {
        "id": "51Uffv8jVSSI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOdYRWDBaSpG",
        "outputId": "95bed569-7b8e-45b0-ad0f-d777bf09bc2e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "|id |sentences                                              |tokenOutput                                                     |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "|0  |hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |\n",
            "|1  |I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|\n",
            "|2  |i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |\n",
            "|3  |here, is,a,list,of,words                               |[here,, is,a,list,of,words]                                     |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = NGram(n=2,inputCol='tokenOutput',outputCol='bigrams')\n",
        "bigram_df = bigram.transform(tokenized)\n",
        "bigram_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8dwSI_uaYyQ",
        "outputId": "013643e7-53e2-4f56-d63e-d413c87092d6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------------------------------+----------------------------------------------------------------+----------------------------------------------------------------------------------------------------------+\n",
            "|id |sentences                                              |tokenOutput                                                     |bigrams                                                                                                   |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+----------------------------------------------------------------------------------------------------------+\n",
            "|0  |hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |[hello i, i am, am happy, happy to, to be, be learning, learning apache, apache spark]                    |\n",
            "|1  |I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|[i enjoy, enjoy learning, learning about, about python, python and, and javascript, javascript progamming]|\n",
            "|2  |i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |[i am, am familiar, familiar with, with machine, machine learning, learning applications]                 |\n",
            "|3  |here, is,a,list,of,words                               |[here,, is,a,list,of,words]                                     |[here, is,a,list,of,words]                                                                                |\n",
            "+---+-------------------------------------------------------+----------------------------------------------------------------+----------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Featue Extraction \n",
        "- TF-IDF"
      ],
      "metadata": {
        "id": "WqtKK8YtbTMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import IDF, HashingTF, Tokenizer"
      ],
      "metadata": {
        "id": "OyNrpRjwbC8O"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df = spark.createDataFrame(\n",
        "    [\n",
        "     (0, 0.0,\"hello i am happy to be learning Apache Spark\"),\n",
        "     (1, 0.0,\"I enjoy learning about python and javascript progamming\"),\n",
        "     (2, 1.0,\"i am familiar with Machine Learning applications\"),\n",
        "     (3, 1.0, \"here, is,a,list,of,words\")\n",
        "    ],\n",
        "    ['id','label','sentences']\n",
        ")\n",
        "\n",
        "sent_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8eD5oEnbjUb",
        "outputId": "9b09fabd-6542-4f30-8abd-7bf680b8f1cb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------------------------------------------------------+\n",
            "|id |label|sentences                                              |\n",
            "+---+-----+-------------------------------------------------------+\n",
            "|0  |0.0  |hello i am happy to be learning Apache Spark           |\n",
            "|1  |0.0  |I enjoy learning about python and javascript progamming|\n",
            "|2  |1.0  |i am familiar with Machine Learning applications       |\n",
            "|3  |1.0  |here, is,a,list,of,words                               |\n",
            "+---+-----+-------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexTokenizer(inputCol='sentences',outputCol='words',pattern=\"\\\\W\")\n",
        "words_df  = tokenizer.transform(sent_df)\n",
        "words_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSfb5ui5fa9P",
        "outputId": "c7fce7e3-d6ed-41f6-9ad2-9e4d686e5907"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "|id |label|sentences                                              |words                                                           |\n",
            "+---+-----+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "|0  |0.0  |hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |\n",
            "|1  |0.0  |I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|\n",
            "|2  |1.0  |i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |\n",
            "|3  |1.0  |here, is,a,list,of,words                               |[here, is, a, list, of, words]                                  |\n",
            "+---+-----+-------------------------------------------------------+----------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hashingTF = HashingTF(inputCol='words',outputCol='rawFeatures', numFeatures=20)\n",
        "featurized = hashingTF.transform(words_df)"
      ],
      "metadata": {
        "id": "A4XvFFRhf_7K"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featurized.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyHwA81rgYhd",
        "outputId": "aa33bbac-eae6-4a59-aa5d-628a2eced8dc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------------------------------------------------------+----------------------------------------------------------------+-----------------------------------------------------------------+\n",
            "|id |label|sentences                                              |words                                                           |rawFeatures                                                      |\n",
            "+---+-----+-------------------------------------------------------+----------------------------------------------------------------+-----------------------------------------------------------------+\n",
            "|0  |0.0  |hello i am happy to be learning Apache Spark           |[hello, i, am, happy, to, be, learning, apache, spark]          |(20,[3,5,6,7,8,9,12,15,16],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
            "|1  |0.0  |I enjoy learning about python and javascript progamming|[i, enjoy, learning, about, python, and, javascript, progamming]|(20,[5,6,9,11,12,14,16],[1.0,1.0,1.0,1.0,1.0,1.0,2.0])           |\n",
            "|2  |1.0  |i am familiar with Machine Learning applications       |[i, am, familiar, with, machine, learning, applications]        |(20,[0,2,5,10,12,16],[1.0,2.0,1.0,1.0,1.0,1.0])                  |\n",
            "|3  |1.0  |here, is,a,list,of,words                               |[here, is, a, list, of, words]                                  |(20,[7,8,9,12,15],[1.0,1.0,1.0,1.0,2.0])                         |\n",
            "+---+-----+-------------------------------------------------------+----------------------------------------------------------------+-----------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf = IDF(inputCol='rawFeatures',outputCol='features')\n",
        "idf_model = idf.fit(featurized)"
      ],
      "metadata": {
        "id": "BjTGvvKmgeuw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescale = idf_model.transform(featurized)\n",
        "rescale.select(\"label\",'features').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jCfJgmBgxpg",
        "outputId": "44581e52-a27d-4381-8d33-81a949af252a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|features                                                                                                                                                                                    |\n",
            "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0.0  |(20,[3,5,6,7,8,9,12,15,16],[0.9162907318741551,0.22314355131420976,0.5108256237659907,0.5108256237659907,0.5108256237659907,0.22314355131420976,0.0,0.5108256237659907,0.22314355131420976])|\n",
            "|0.0  |(20,[5,6,9,11,12,14,16],[0.22314355131420976,0.5108256237659907,0.22314355131420976,0.9162907318741551,0.0,0.9162907318741551,0.44628710262841953])                                         |\n",
            "|1.0  |(20,[0,2,5,10,12,16],[0.9162907318741551,1.8325814637483102,0.22314355131420976,0.9162907318741551,0.0,0.22314355131420976])                                                                |\n",
            "|1.0  |(20,[7,8,9,12,15],[0.5108256237659907,0.5108256237659907,0.22314355131420976,0.0,1.0216512475319814])                                                                                       |\n",
            "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count Vectorization"
      ],
      "metadata": {
        "id": "GSxMxWyjhKdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer"
      ],
      "metadata": {
        "id": "3qNIloX5g8IV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(\n",
        "    [\n",
        "     (0,list('abcde')),\n",
        "      (1,list('abbbccddee')),\n",
        "    ],\n",
        "    ['id','words']\n",
        ")\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLiLEy5-hXYm",
        "outputId": "70aa62ba-9568-4f01-f56f-43e5565e3cb9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|               words|\n",
            "+---+--------------------+\n",
            "|  0|     [a, b, c, d, e]|\n",
            "|  1|[a, b, b, b, c, c...|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(inputCol='words', outputCol='features', vocabSize=5,minDF=2.0)\n",
        "model = cv.fit(df)\n",
        "res = model.transform(df)\n",
        "res.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a27p9gLFhkYL",
        "outputId": "ba662780-cd7a-410b-8b32-adcdf64758de"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------+-------------------------------------+\n",
            "|id |words                         |features                             |\n",
            "+---+------------------------------+-------------------------------------+\n",
            "|0  |[a, b, c, d, e]               |(5,[0,1,2,3,4],[1.0,1.0,1.0,1.0,1.0])|\n",
            "|1  |[a, b, b, b, c, c, d, d, e, e]|(5,[0,1,2,3,4],[3.0,2.0,2.0,2.0,1.0])|\n",
            "+---+------------------------------+-------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TI-COmF1h3-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}